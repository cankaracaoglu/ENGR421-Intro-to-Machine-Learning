{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5ea259be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dda3f835",
   "metadata": {},
   "source": [
    "## Importing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0eeff8a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#read data \n",
    "#x = np.genfromtxt(\"hw01_data_points.csv\", dtype=type(chr), delimiter = \",\", skip_header = 0)\n",
    "x =  np.char.strip(np.genfromtxt('hw01_data_points.csv',delimiter=',',dtype=str))\n",
    "y = np.genfromtxt(\"hw01_class_labels.csv\", delimiter = \",\", skip_header = 0)\n",
    "\n",
    "#number of elements\n",
    "N = x.shape[0]\n",
    "#Diemension of the data points\n",
    "D = x.shape[1]\n",
    "#Number of class labels (It should be 2 for a binary classification)\n",
    "K = np.unique(y).shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e876fec",
   "metadata": {},
   "source": [
    "## Divide training and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "36f11156",
   "metadata": {},
   "outputs": [],
   "source": [
    "#seperate x\n",
    "x_training = x[:300]\n",
    "x_test = x[300:]\n",
    "#Number of samples\n",
    "N_training = x_training.shape[0]\n",
    "N_test = x_test.shape[0]\n",
    "#seperate y\n",
    "y_training = y[:300].astype(int)\n",
    "y_test = y[300:].astype(int)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abe493e4",
   "metadata": {},
   "source": [
    "## Estimate model parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f2c41c9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.28       0.68       0.09333333 0.56666667 0.68       0.14\n",
      "  0.19333333]\n",
      " [0.22666667 0.24       0.26666667 0.18666667 0.20666667 0.18\n",
      "  0.26      ]]\n",
      "[[0.4        0.08666667 0.01333333 0.02       0.12       0.06\n",
      "  0.08      ]\n",
      " [0.16       0.23333333 0.09333333 0.17333333 0.21333333 0.26666667\n",
      "  0.19333333]]\n",
      "[[0.21333333 0.09333333 0.82666667 0.35333333 0.1        0.76\n",
      "  0.20666667]\n",
      " [0.29333333 0.27333333 0.22666667 0.36       0.2        0.23333333\n",
      "  0.2       ]]\n",
      "[[0.10666667 0.14       0.06666667 0.06       0.1        0.04\n",
      "  0.52      ]\n",
      " [0.32       0.25333333 0.41333333 0.28       0.38       0.32\n",
      "  0.34666667]]\n",
      "[0.5, 0.5]\n"
     ]
    }
   ],
   "source": [
    "def func(nuc):\n",
    "    array = np.zeros((K,D))\n",
    "    for i in range(K):\n",
    "        for j in range(D):\n",
    "            sum = 0\n",
    "            for k in range(N_training):\n",
    "                if(y_training[k] == i + 1):\n",
    "                    if(x_training[k][j] == nuc):\n",
    "                        sum = sum + 1\n",
    "                array[i][j] = sum/(x_training[y_training == (i + 1)]).shape[0]\n",
    "    return array\n",
    "\n",
    "pAcd = func('A')\n",
    "pCcd = func('C')\n",
    "pGcd = func('G')\n",
    "pTcd = func('T')\n",
    "\n",
    "class_priors = [((x_training[y_training == 1]).shape[0])/N_training,((x_training[y_training == 2]).shape[0])/N_training]\n",
    "\n",
    "print(pAcd) \n",
    "print(pCcd)\n",
    "print(pGcd)\n",
    "print(pTcd)\n",
    "print(class_priors)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76864b28",
   "metadata": {},
   "source": [
    "## Score Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5b7d355b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define the score function\n",
    "def g(x,c):\n",
    "    score = 0\n",
    "    for i in range(len(x)):\n",
    "        n = x[i]\n",
    "        if n == 'A':\n",
    "            score += np.log(pAcd[c-1][i])\n",
    "        if n == 'G':\n",
    "            score += np.log(pGcd[c-1][i])\n",
    "        if n == 'C':\n",
    "            score += np.log(pCcd[c-1][i])\n",
    "        if n == 'T':\n",
    "            score += np.log(pTcd[c-1][i])\n",
    "    return score + np.log(class_priors[c - 1])     \n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7c72734",
   "metadata": {},
   "source": [
    "## Evaluation of Training Scores and Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "06fa420b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_truth    1    2\n",
      "y_pred           \n",
      "1        145   14\n",
      "2          5  136\n"
     ]
    }
   ],
   "source": [
    "#Create the prediction array\n",
    "y_predicted = []\n",
    "for x in x_training:\n",
    "    if(g(x,1) > g(x,2)):\n",
    "        y_predicted.append(1)\n",
    "    else:\n",
    "        y_predicted.append(2)\n",
    "\n",
    "# calculate confusion matrix\n",
    "confusion_matrix = pd.crosstab(np.asarray(y_predicted).T, y_training.T, \n",
    "                               rownames = [\"y_pred\"], \n",
    "                               colnames = [\"y_truth\"])\n",
    "\n",
    "print(confusion_matrix)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bd7f637",
   "metadata": {},
   "source": [
    "## Test Scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "defeab25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_truth   1   2\n",
      "y_pred         \n",
      "1        48   8\n",
      "2         2  42\n"
     ]
    }
   ],
   "source": [
    "#Create the prediction array\n",
    "y_predicted = []\n",
    "for x in x_test:\n",
    "    if(g(x,1) > g(x,2)):\n",
    "        y_predicted.append(1)\n",
    "    else:\n",
    "        y_predicted.append(2)\n",
    "        \n",
    "# calculate confusion matrix\n",
    "confusion_matrix = pd.crosstab(np.asarray(y_predicted).T, y_test.T, \n",
    "                               rownames = [\"y_pred\"], \n",
    "                               colnames = [\"y_truth\"])\n",
    "\n",
    "print(confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e8d810f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
